{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZnFn/ML-mini-projects/blob/main/Challenge_5_Stroke_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g2RQRSltgja"
      },
      "source": [
        "# **Challenge of the Week: Full DL Solution**\n",
        "\n",
        "---\n",
        "###**Case Study:** Stroke Prediction\n",
        "\n",
        "**Objective:** The goal of this challenge is to walk you through a case study where you can apply the deep learning concepts that you learned about during the week. By the end of this challenge, you would have developed a solution that predicts if a person will have a stroke or not.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSCD88NxJjFo"
      },
      "source": [
        "**Dataset Explanation:** We will be using the stroke dataset. Its features are:\n",
        "\n",
        "\n",
        "* **id:** unique identifier\n",
        "* **gender:** \"Male\", \"Female\" or \"Other\"\n",
        "* **age:** age of the patient\n",
        "* **hypertension:** 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n",
        "* **heart_disease:** 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n",
        "* **ever_married:** \"No\" or \"Yes\"\n",
        "* **work_type:** \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n",
        "* **Residence_type:** \"Rural\" or \"Urban\"\n",
        "* **avg_glucose_level:** average glucose level in blood\n",
        "* **bmi:** body mass index\n",
        "* **smoking_status:** \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n",
        "* **stroke:** 1 if the patient had a stroke or 0 if not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBvX5nCYt8cT"
      },
      "source": [
        "#Importing Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaPfsfvXK2_0"
      },
      "source": [
        "We start by importing the libraries: numpy and pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMQuUG7OtfrG"
      },
      "source": [
        "#Test Your Zaka\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY902S7vBq7i",
        "outputId": "f636c1f5-970f-48cf-b87a-de84a0e24b86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-RxAH5auFFy"
      },
      "source": [
        "#Loading the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_jj2t6zK6zy"
      },
      "source": [
        "We load the dataset from a csv file, and see its first rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQVo1CAJt7s8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9a9e1792-593c-4a5d-f35c-2101fb572195"
      },
      "source": [
        "#Test Your Zaka\n",
        "path = '/content/drive/MyDrive/healthcare-dataset-stroke-data.csv'\n",
        "df = pd.read_csv(path)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
              "0   9046    Male  67.0             0              1          Yes   \n",
              "1  51676  Female  61.0             0              0          Yes   \n",
              "2  31112    Male  80.0             0              1          Yes   \n",
              "3  60182  Female  49.0             0              0          Yes   \n",
              "4   1665  Female  79.0             1              0          Yes   \n",
              "\n",
              "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
              "0        Private          Urban             228.69  36.6  formerly smoked   \n",
              "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
              "2        Private          Rural             105.92  32.5     never smoked   \n",
              "3        Private          Urban             171.23  34.4           smokes   \n",
              "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
              "\n",
              "   stroke  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39c778a9-a717-466e-aebb-b37d1d4959db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>work_type</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9046</td>\n",
              "      <td>Male</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>228.69</td>\n",
              "      <td>36.6</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51676</td>\n",
              "      <td>Female</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>202.21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31112</td>\n",
              "      <td>Male</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Rural</td>\n",
              "      <td>105.92</td>\n",
              "      <td>32.5</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60182</td>\n",
              "      <td>Female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>171.23</td>\n",
              "      <td>34.4</td>\n",
              "      <td>smokes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1665</td>\n",
              "      <td>Female</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>174.12</td>\n",
              "      <td>24.0</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39c778a9-a717-466e-aebb-b37d1d4959db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39c778a9-a717-466e-aebb-b37d1d4959db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39c778a9-a717-466e-aebb-b37d1d4959db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6gAyBGtubI7"
      },
      "source": [
        "#Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ_93CvuLF3j"
      },
      "source": [
        "Now we start the exploratory data analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2925yVCdud0a"
      },
      "source": [
        "###Shape of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ0hWvVALJy4"
      },
      "source": [
        "First, you need to know the shape of our data (How many examples and features do we have)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pvWR3PKuQEy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd51fc6a-1bc5-403e-826c-b6d2eb1488b0"
      },
      "source": [
        "#Test Your Zaka\n",
        "rows = df.shape[0]\n",
        "cols = df.shape[1]\n",
        "print(f'we have {rows} rows and {cols} columns')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we have 5110 rows and 12 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUy4oI5xukRr"
      },
      "source": [
        "###Types of different Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1q10ievLTTs"
      },
      "source": [
        "See the type of each of your features and see if you have any nulls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8snoohouhUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb8884f4-5459-4f94-89e3-c873a6cec422"
      },
      "source": [
        "#Test Your Zaka\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5110 entries, 0 to 5109\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   id                 5110 non-null   int64  \n",
            " 1   gender             5110 non-null   object \n",
            " 2   age                5110 non-null   float64\n",
            " 3   hypertension       5110 non-null   int64  \n",
            " 4   heart_disease      5110 non-null   int64  \n",
            " 5   ever_married       5110 non-null   object \n",
            " 6   work_type          5110 non-null   object \n",
            " 7   Residence_type     5110 non-null   object \n",
            " 8   avg_glucose_level  5110 non-null   float64\n",
            " 9   bmi                4909 non-null   float64\n",
            " 10  smoking_status     5110 non-null   object \n",
            " 11  stroke             5110 non-null   int64  \n",
            "dtypes: float64(3), int64(4), object(5)\n",
            "memory usage: 479.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkrEh6RYygms"
      },
      "source": [
        "###Dealing with categorical variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7rtFrHVLg5U"
      },
      "source": [
        "Now we will walk through the categorical variables that we have to see the categories and the counts of each of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5uIMEU-gYEJ"
      },
      "source": [
        "'smoking_status'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlSfSQ35ykgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff59cd0-5b6a-4a19-a889-4f970c0b14ac"
      },
      "source": [
        "#Test Your Zaka\n",
        "df.smoking_status.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "never smoked       1892\n",
              "Unknown            1544\n",
              "formerly smoked     885\n",
              "smokes              789\n",
              "Name: smoking_status, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1yf6OU5geTr"
      },
      "source": [
        "'Residence_type'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg0xlLNUy7AF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2cee48-02ff-4459-b3c7-9bea78c04e19"
      },
      "source": [
        "#Test Your Zaka\n",
        "df.Residence_type.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Urban    2596\n",
              "Rural    2514\n",
              "Name: Residence_type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82ovosaVgjC8"
      },
      "source": [
        "'work_type'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T72r_mkrzF9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c24e1c-c709-46c1-db32-815a59d8f6f6"
      },
      "source": [
        "#Test Your Zaka\n",
        "df.work_type.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Private          2925\n",
              "Self-employed     819\n",
              "children          687\n",
              "Govt_job          657\n",
              "Never_worked       22\n",
              "Name: work_type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oa7__UPgnu8"
      },
      "source": [
        "'ever_married'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0kpR57LzQE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0255c1a-3856-429b-c028-6e5d282fe16b"
      },
      "source": [
        "#Test Your Zaka\n",
        "df.ever_married.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Yes    3353\n",
              "No     1757\n",
              "Name: ever_married, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqUD-N4ygrxB"
      },
      "source": [
        "'hypertension'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQIoAs8y3igG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25919f11-a030-4487-af58-f5b29e32c28e"
      },
      "source": [
        "#Test Your Zaka\n",
        "df.hypertension.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4612\n",
              "1     498\n",
              "Name: hypertension, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmyP9Nfsg29X"
      },
      "source": [
        "'heart_disease'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEhNH46j3p3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e1bd63-a0d8-4f9e-89fe-9c2ef69615b4"
      },
      "source": [
        "#Test Your Zaka\n",
        "df.heart_disease.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4834\n",
              "1     276\n",
              "Name: heart_disease, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8Oql1Xag94S"
      },
      "source": [
        "'stroke'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cI7uJvA3Njv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f62035-aa18-4c39-b9fc-e204a78d75fc"
      },
      "source": [
        "#Test Your Zaka\n",
        "df.stroke.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4861\n",
              "1     249\n",
              "Name: stroke, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6jD-fR_k49a"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs4Tnvhbk-Ew"
      },
      "source": [
        "###Dealing with Nulls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21da4C_Bzd-u"
      },
      "source": [
        "####Encoding Categorical Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaNk4gWCLqe4"
      },
      "source": [
        "Here you will encode those categorical variables to be able to use them to train our DL model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nJtOvxdzi_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a196fe3-13b0-4299-beae-b0a211919f23"
      },
      "source": [
        "#Test Your Zaka\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "df['gender']= encoder.fit_transform(df['gender'])\n",
        "df['ever_married'] = encoder.fit_transform(df['ever_married'])\n",
        "df['work_type'] = encoder.fit_transform(df['work_type'])\n",
        "df['Residence_type'] = encoder.fit_transform(df['Residence_type'])\n",
        "df['smoking_status'] = encoder.fit_transform(df['smoking_status'])\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5110 entries, 0 to 5109\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   id                 5110 non-null   int64  \n",
            " 1   gender             5110 non-null   int64  \n",
            " 2   age                5110 non-null   float64\n",
            " 3   hypertension       5110 non-null   int64  \n",
            " 4   heart_disease      5110 non-null   int64  \n",
            " 5   ever_married       5110 non-null   int64  \n",
            " 6   work_type          5110 non-null   int64  \n",
            " 7   Residence_type     5110 non-null   int64  \n",
            " 8   avg_glucose_level  5110 non-null   float64\n",
            " 9   bmi                4909 non-null   float64\n",
            " 10  smoking_status     5110 non-null   int64  \n",
            " 11  stroke             5110 non-null   int64  \n",
            "dtypes: float64(3), int64(9)\n",
            "memory usage: 479.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtJKDDePlHJl"
      },
      "source": [
        "Fill the nulls with the mean value, and make sure you have no nulls anymore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOUE6TcrlIRo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44e36063-0fd2-4e0a-b793-f2d88a75bd35"
      },
      "source": [
        "#Test Your Zaka\n",
        "mean = df['bmi'].mean()\n",
        "df['bmi'].fillna(value=mean, inplace=True)\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                   0\n",
              "gender               0\n",
              "age                  0\n",
              "hypertension         0\n",
              "heart_disease        0\n",
              "ever_married         0\n",
              "work_type            0\n",
              "Residence_type       0\n",
              "avg_glucose_level    0\n",
              "bmi                  0\n",
              "smoking_status       0\n",
              "stroke               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1GOfAgt4M-Q"
      },
      "source": [
        "###Normalizing Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPpkMCXELwty"
      },
      "source": [
        "Now you normalize the input data by dividing with the max value of each column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtI_XA-m33Bx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "e05d6b77-adf7-4273-bb04-11abc276ec3b"
      },
      "source": [
        "#Test Your Zaka\n",
        "max= df.max()\n",
        "df = df.divide(max)\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                id       gender          age  hypertension  heart_disease  \\\n",
              "count  5110.000000  5110.000000  5110.000000   5110.000000    5110.000000   \n",
              "mean      0.500656     0.207143     0.527154      0.097456       0.054012   \n",
              "std       0.290125     0.246522     0.275764      0.296607       0.226063   \n",
              "min       0.000919     0.000000     0.000976      0.000000       0.000000   \n",
              "25%       0.243231     0.000000     0.304878      0.000000       0.000000   \n",
              "50%       0.506334     0.000000     0.548780      0.000000       0.000000   \n",
              "75%       0.749685     0.500000     0.743902      0.000000       0.000000   \n",
              "max       1.000000     1.000000     1.000000      1.000000       1.000000   \n",
              "\n",
              "       ever_married    work_type  Residence_type  avg_glucose_level  \\\n",
              "count   5110.000000  5110.000000     5110.000000        5110.000000   \n",
              "mean       0.656164     0.541928        0.508023           0.390622   \n",
              "std        0.475034     0.272573        0.499985           0.166643   \n",
              "min        0.000000     0.000000        0.000000           0.202841   \n",
              "25%        0.000000     0.500000        0.000000           0.284261   \n",
              "50%        1.000000     0.500000        1.000000           0.338136   \n",
              "75%        1.000000     0.750000        1.000000           0.419850   \n",
              "max        1.000000     1.000000        1.000000           1.000000   \n",
              "\n",
              "               bmi  smoking_status       stroke  \n",
              "count  5110.000000     5110.000000  5110.000000  \n",
              "mean      0.296037        0.458969     0.048728  \n",
              "std       0.078873        0.357178     0.215320  \n",
              "min       0.105533        0.000000     0.000000  \n",
              "25%       0.243852        0.000000     0.000000  \n",
              "50%       0.290984        0.666667     0.000000  \n",
              "75%       0.336066        0.666667     0.000000  \n",
              "max       1.000000        1.000000     1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7cc5ca7f-0afe-4e9d-ae71-0d88e783b3e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>work_type</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.500656</td>\n",
              "      <td>0.207143</td>\n",
              "      <td>0.527154</td>\n",
              "      <td>0.097456</td>\n",
              "      <td>0.054012</td>\n",
              "      <td>0.656164</td>\n",
              "      <td>0.541928</td>\n",
              "      <td>0.508023</td>\n",
              "      <td>0.390622</td>\n",
              "      <td>0.296037</td>\n",
              "      <td>0.458969</td>\n",
              "      <td>0.048728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.290125</td>\n",
              "      <td>0.246522</td>\n",
              "      <td>0.275764</td>\n",
              "      <td>0.296607</td>\n",
              "      <td>0.226063</td>\n",
              "      <td>0.475034</td>\n",
              "      <td>0.272573</td>\n",
              "      <td>0.499985</td>\n",
              "      <td>0.166643</td>\n",
              "      <td>0.078873</td>\n",
              "      <td>0.357178</td>\n",
              "      <td>0.215320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000919</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000976</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.202841</td>\n",
              "      <td>0.105533</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.243231</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.304878</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.284261</td>\n",
              "      <td>0.243852</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.506334</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.548780</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.338136</td>\n",
              "      <td>0.290984</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.749685</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.743902</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.419850</td>\n",
              "      <td>0.336066</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7cc5ca7f-0afe-4e9d-ae71-0d88e783b3e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7cc5ca7f-0afe-4e9d-ae71-0d88e783b3e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7cc5ca7f-0afe-4e9d-ae71-0d88e783b3e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KICuY0lg5nUD"
      },
      "source": [
        "###Removing Unnecessary Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua71U2YxL5Ls"
      },
      "source": [
        "From the features that we have, remove one that is irrelevant for our predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AHNqYbh5sE7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f2f60d36-0e50-4a16-d6cc-e75eb8e83837"
      },
      "source": [
        "#Test Your Zaka\n",
        "df.drop(['id'],axis=1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   gender       age  hypertension  heart_disease  ever_married  work_type  \\\n",
              "0     0.5  0.817073           0.0            1.0           1.0       0.50   \n",
              "1     0.0  0.743902           0.0            0.0           1.0       0.75   \n",
              "2     0.5  0.975610           0.0            1.0           1.0       0.50   \n",
              "3     0.0  0.597561           0.0            0.0           1.0       0.50   \n",
              "4     0.0  0.963415           1.0            0.0           1.0       0.75   \n",
              "\n",
              "   Residence_type  avg_glucose_level       bmi  smoking_status  stroke  \n",
              "0             1.0           0.841577  0.375000        0.333333     1.0  \n",
              "1             0.0           0.744130  0.296037        0.666667     1.0  \n",
              "2             0.0           0.389784  0.332992        0.666667     1.0  \n",
              "3             1.0           0.630124  0.352459        1.000000     1.0  \n",
              "4             0.0           0.640760  0.245902        0.666667     1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73a4a6fe-73fb-4d3a-8763-cbaf1e3a64e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>work_type</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.817073</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.841577</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.743902</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.744130</td>\n",
              "      <td>0.296037</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.975610</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.389784</td>\n",
              "      <td>0.332992</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.597561</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.630124</td>\n",
              "      <td>0.352459</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.963415</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.640760</td>\n",
              "      <td>0.245902</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73a4a6fe-73fb-4d3a-8763-cbaf1e3a64e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73a4a6fe-73fb-4d3a-8763-cbaf1e3a64e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73a4a6fe-73fb-4d3a-8763-cbaf1e3a64e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k-KoLpH5C9R"
      },
      "source": [
        "#Building the DL Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI2VtlafMBeN"
      },
      "source": [
        "Now it's time to build the actual model, and observe a summary of it.<br>\n",
        "The sizes of the **hidden** layers that you should use are: [32,16,8,4,2].\n",
        "The activation for each of those hidden layers is 'relu'\n",
        "<br>\n",
        "Print the summary of your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZvKqqT65E0W"
      },
      "source": [
        "#Test Your Zaka\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(32, activation='relu', input_dim=10))\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "  model.add(Dense(8, activation='relu'))\n",
        "  model.add(Dense(4, activation='relu'))\n",
        "  model.add(Dense(2, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD57fE2n7QP4"
      },
      "source": [
        "###Compiling the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seGmh1x1-qH9"
      },
      "source": [
        "Now we compile the model. Here we want to measure the accuracy as well as the precision and recall to know better about the performance of our model.\n",
        "We will use 'adam' as optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woSsSTEm61_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c595f39-2d2a-4509-8c86-e2cdea082819"
      },
      "source": [
        "#Test Your Zaka\n",
        "model = create_model()\n",
        "model.compile(optimizer = 'adam', loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_192 (Dense)           (None, 32)                352       \n",
            "                                                                 \n",
            " dense_193 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dense_194 (Dense)           (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_195 (Dense)           (None, 4)                 36        \n",
            "                                                                 \n",
            " dense_196 (Dense)           (None, 2)                 10        \n",
            "                                                                 \n",
            " dense_197 (Dense)           (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,065\n",
            "Trainable params: 1,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5zevRH57X8v"
      },
      "source": [
        "###Fitting the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhaEU26KMUWK"
      },
      "source": [
        "we split our dataset between training and testing, and we fit the model on training data (70%), and validate on the testing data (30%). The training happens for 15 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsVOVfn47MLn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d65e83a9-b1ee-4f38-b040-44df8293e1b3"
      },
      "source": [
        "#Test Your Zaka\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df.iloc[:,0:-1]\n",
        "Y = df.iloc[:,-1]\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=42)\n",
        "model.fit(x_train, y_train,validation_data=(x_test, y_test), epochs=15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "112/112 [==============================] - 2s 7ms/step - loss: 0.4168 - accuracy: 0.9530 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2515 - val_accuracy: 0.9419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/15\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.2004 - accuracy: 0.9553 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2304 - val_accuracy: 0.9419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/15\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.1864 - accuracy: 0.9553 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2148 - val_accuracy: 0.9419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/15\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.1768 - accuracy: 0.9553 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2042 - val_accuracy: 0.9419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/15\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.1692 - accuracy: 0.9553 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1987 - val_accuracy: 0.9419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/15\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.1620 - accuracy: 0.9553 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1928 - val_accuracy: 0.9419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/15\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1599 - accuracy: 0.9553 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1886 - val_accuracy: 0.9419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/15\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1550 - accuracy: 0.9553 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1905 - val_accuracy: 0.9419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 9/15\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1535 - accuracy: 0.9553 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1827 - val_accuracy: 0.9419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 10/15\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.1517 - accuracy: 0.9553 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1915 - val_accuracy: 0.9419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 11/15\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1498 - accuracy: 0.9553 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1840 - val_accuracy: 0.9419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 12/15\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1500 - accuracy: 0.9553 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1911 - val_accuracy: 0.9419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 13/15\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.1485 - accuracy: 0.9553 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1798 - val_accuracy: 0.9419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 14/15\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9553 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1787 - val_accuracy: 0.9419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 15/15\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9553 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1786 - val_accuracy: 0.9419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5bcca2a790>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sPVIoABAa8Q"
      },
      "source": [
        "What can you deduce from the results you obtained?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owY9hyWFimQQ"
      },
      "source": [
        "**[Share your Zaka here]**\n",
        "\n",
        "**Since our precision is 0 this means that our model is not being able to correctly predict positive cases**\n",
        "\n",
        "**Since our recall is 0 this means the nodel is not being able to predict positive cases**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voqUo00lAqCZ"
      },
      "source": [
        "#Improving DL Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IImSYWQGBSz6"
      },
      "source": [
        "###Checking For Data Imbalance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHxCONODMkNN"
      },
      "source": [
        "Plot a histogram that shows the distribution of 'stroke' column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bF6G8c58SOE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "dd55a76b-1415-455c-d5d0-ddc76844ffa7"
      },
      "source": [
        "#Test Your Zaka\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(Y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzZBB5GMCOld"
      },
      "source": [
        "We have a huge imbalance in the data, this is why we fix it with oversamppling and undersampling.\n",
        "\n",
        "This time, you will learn to oversample using the SMOTE() function instead of random oversampling, and this is because SMOTE will generate new data based on the data that we have, so we avoid overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w66slO25jE1O"
      },
      "source": [
        "After doing that, plot the new histogram showing the proportions of people having stroke or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US4xON4LBX8I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "282fd93e-9c19-40bb-d196-96ebde26d6af"
      },
      "source": [
        "#Test Your Zaka\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state=42)\n",
        "x_new, y_new = sm.fit_resample(X,Y)\n",
        "plt.hist(y_new)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6MOHwo_Ew08"
      },
      "source": [
        "Now we will fit our same model on the new balanced data that we have, with the same conditions we had before (train/test splits, epochs, etc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26YTispLEm9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc05ee81-4e13-44b0-c633-52d4fb234c6c"
      },
      "source": [
        "#Test Your Zaka\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_new, y_new, test_size=0.3, random_state=42)\n",
        "model.fit(x_train, y_train,validation_data=(x_test, y_test), epochs=15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "213/213 [==============================] - 1s 7ms/step - loss: 0.3953 - accuracy: 0.8100 - precision: 0.7755 - recall: 0.8724 - val_loss: 0.3919 - val_accuracy: 0.8214 - val_precision: 0.7844 - val_recall: 0.8870\n",
            "Epoch 2/15\n",
            "213/213 [==============================] - 1s 7ms/step - loss: 0.3921 - accuracy: 0.8119 - precision: 0.7789 - recall: 0.8709 - val_loss: 0.3950 - val_accuracy: 0.8183 - val_precision: 0.7624 - val_recall: 0.9253\n",
            "Epoch 3/15\n",
            "213/213 [==============================] - 1s 5ms/step - loss: 0.3908 - accuracy: 0.8113 - precision: 0.7769 - recall: 0.8733 - val_loss: 0.3895 - val_accuracy: 0.8252 - val_precision: 0.7893 - val_recall: 0.8877\n",
            "Epoch 4/15\n",
            "213/213 [==============================] - 1s 5ms/step - loss: 0.3877 - accuracy: 0.8145 - precision: 0.7783 - recall: 0.8794 - val_loss: 0.3874 - val_accuracy: 0.8231 - val_precision: 0.7843 - val_recall: 0.8918\n",
            "Epoch 5/15\n",
            "213/213 [==============================] - 2s 7ms/step - loss: 0.3867 - accuracy: 0.8150 - precision: 0.7798 - recall: 0.8777 - val_loss: 0.3866 - val_accuracy: 0.8207 - val_precision: 0.7682 - val_recall: 0.9192\n",
            "Epoch 6/15\n",
            "213/213 [==============================] - 1s 6ms/step - loss: 0.3819 - accuracy: 0.8198 - precision: 0.7821 - recall: 0.8865 - val_loss: 0.3851 - val_accuracy: 0.8204 - val_precision: 0.7727 - val_recall: 0.9082\n",
            "Epoch 7/15\n",
            "213/213 [==============================] - 1s 5ms/step - loss: 0.3780 - accuracy: 0.8193 - precision: 0.7826 - recall: 0.8839 - val_loss: 0.3813 - val_accuracy: 0.8303 - val_precision: 0.7951 - val_recall: 0.8904\n",
            "Epoch 8/15\n",
            "213/213 [==============================] - 1s 5ms/step - loss: 0.3743 - accuracy: 0.8234 - precision: 0.7902 - recall: 0.8803 - val_loss: 0.3812 - val_accuracy: 0.8324 - val_precision: 0.8090 - val_recall: 0.8705\n",
            "Epoch 9/15\n",
            "213/213 [==============================] - 1s 3ms/step - loss: 0.3741 - accuracy: 0.8242 - precision: 0.7888 - recall: 0.8853 - val_loss: 0.3767 - val_accuracy: 0.8293 - val_precision: 0.7823 - val_recall: 0.9130\n",
            "Epoch 10/15\n",
            "213/213 [==============================] - 1s 4ms/step - loss: 0.3715 - accuracy: 0.8259 - precision: 0.7916 - recall: 0.8844 - val_loss: 0.3804 - val_accuracy: 0.8276 - val_precision: 0.7898 - val_recall: 0.8932\n",
            "Epoch 11/15\n",
            "213/213 [==============================] - 1s 3ms/step - loss: 0.3712 - accuracy: 0.8248 - precision: 0.7868 - recall: 0.8909 - val_loss: 0.3745 - val_accuracy: 0.8368 - val_precision: 0.7946 - val_recall: 0.9089\n",
            "Epoch 12/15\n",
            "213/213 [==============================] - 1s 3ms/step - loss: 0.3660 - accuracy: 0.8309 - precision: 0.7939 - recall: 0.8936 - val_loss: 0.3783 - val_accuracy: 0.8255 - val_precision: 0.8011 - val_recall: 0.8664\n",
            "Epoch 13/15\n",
            "213/213 [==============================] - 1s 4ms/step - loss: 0.3628 - accuracy: 0.8275 - precision: 0.7917 - recall: 0.8886 - val_loss: 0.3718 - val_accuracy: 0.8258 - val_precision: 0.7843 - val_recall: 0.8993\n",
            "Epoch 14/15\n",
            "213/213 [==============================] - 1s 4ms/step - loss: 0.3632 - accuracy: 0.8300 - precision: 0.7964 - recall: 0.8865 - val_loss: 0.3714 - val_accuracy: 0.8365 - val_precision: 0.7988 - val_recall: 0.9000\n",
            "Epoch 15/15\n",
            "213/213 [==============================] - 1s 4ms/step - loss: 0.3591 - accuracy: 0.8337 - precision: 0.7997 - recall: 0.8900 - val_loss: 0.3755 - val_accuracy: 0.8272 - val_precision: 0.7922 - val_recall: 0.8877\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5bca51d250>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhfhpIaWGtz2"
      },
      "source": [
        "Comment the performance you obtained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwQClRsEjkUb"
      },
      "source": [
        "**[Share your Zaka here]**\n",
        "\n",
        "**It's true that our accuracy decreased but out precision and recall improved**\n",
        "\n",
        "**Now our model can predict positive values correctly and much better**\n",
        "\n",
        "**The val recall, the val accuracy and val precision are approximetly the same as that on training set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngJVLbRKG7U_"
      },
      "source": [
        "###Model Design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMdcXspCHxIo"
      },
      "source": [
        "Now you will introduce batch normalization after each layer of your network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK78-g-hHrmq"
      },
      "source": [
        "#Test Your Zaka\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "def batch_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(32, activation='relu', input_dim=10))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(4, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(2, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy', optimizer = 'adam',  metrics=['accuracy', 'Precision', 'Recall'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3uBII4wJPbk"
      },
      "source": [
        "Let's train the model with the same conditions as before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REDrQVWLJLs5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fdc2d16-9bb2-4002-c435-7bbc63631952"
      },
      "source": [
        "#Test Your Zaka\n",
        "modelb = batch_model()\n",
        "modelb.fit(x_train, y_train,validation_data=(x_test, y_test), epochs=15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "213/213 [==============================] - 4s 7ms/step - loss: 0.5948 - accuracy: 0.6980 - precision: 0.6795 - recall: 0.7492 - val_loss: 0.5761 - val_accuracy: 0.7230 - val_precision: 0.6501 - val_recall: 0.9671\n",
            "Epoch 2/15\n",
            "213/213 [==============================] - 1s 5ms/step - loss: 0.4949 - accuracy: 0.7691 - precision: 0.7282 - recall: 0.8586 - val_loss: 0.4803 - val_accuracy: 0.7785 - val_precision: 0.7200 - val_recall: 0.9123\n",
            "Epoch 3/15\n",
            "213/213 [==============================] - 1s 5ms/step - loss: 0.4693 - accuracy: 0.7813 - precision: 0.7430 - recall: 0.8600 - val_loss: 0.4577 - val_accuracy: 0.7881 - val_precision: 0.7306 - val_recall: 0.9137\n",
            "Epoch 4/15\n",
            "213/213 [==============================] - 1s 5ms/step - loss: 0.4562 - accuracy: 0.7885 - precision: 0.7461 - recall: 0.8744 - val_loss: 0.4328 - val_accuracy: 0.8012 - val_precision: 0.7699 - val_recall: 0.8596\n",
            "Epoch 5/15\n",
            "213/213 [==============================] - 1s 6ms/step - loss: 0.4462 - accuracy: 0.7888 - precision: 0.7518 - recall: 0.8621 - val_loss: 0.4255 - val_accuracy: 0.8046 - val_precision: 0.7563 - val_recall: 0.8993\n",
            "Epoch 6/15\n",
            "213/213 [==============================] - 1s 5ms/step - loss: 0.4418 - accuracy: 0.7950 - precision: 0.7548 - recall: 0.8736 - val_loss: 0.4246 - val_accuracy: 0.8091 - val_precision: 0.7676 - val_recall: 0.8870\n",
            "Epoch 7/15\n",
            "213/213 [==============================] - 1s 6ms/step - loss: 0.4306 - accuracy: 0.8010 - precision: 0.7629 - recall: 0.8733 - val_loss: 0.4203 - val_accuracy: 0.8152 - val_precision: 0.7717 - val_recall: 0.8959\n",
            "Epoch 8/15\n",
            "213/213 [==============================] - 1s 7ms/step - loss: 0.4205 - accuracy: 0.8073 - precision: 0.7691 - recall: 0.8783 - val_loss: 0.4065 - val_accuracy: 0.8173 - val_precision: 0.7687 - val_recall: 0.9082\n",
            "Epoch 9/15\n",
            "213/213 [==============================] - 2s 10ms/step - loss: 0.4178 - accuracy: 0.8065 - precision: 0.7702 - recall: 0.8733 - val_loss: 0.3989 - val_accuracy: 0.8245 - val_precision: 0.7948 - val_recall: 0.8753\n",
            "Epoch 10/15\n",
            "213/213 [==============================] - 2s 8ms/step - loss: 0.4211 - accuracy: 0.8081 - precision: 0.7700 - recall: 0.8783 - val_loss: 0.4066 - val_accuracy: 0.8162 - val_precision: 0.7584 - val_recall: 0.9288\n",
            "Epoch 11/15\n",
            "213/213 [==============================] - 1s 5ms/step - loss: 0.4117 - accuracy: 0.8126 - precision: 0.7796 - recall: 0.8715 - val_loss: 0.3879 - val_accuracy: 0.8289 - val_precision: 0.7994 - val_recall: 0.8788\n",
            "Epoch 12/15\n",
            "213/213 [==============================] - 1s 7ms/step - loss: 0.4104 - accuracy: 0.8123 - precision: 0.7761 - recall: 0.8777 - val_loss: 0.3857 - val_accuracy: 0.8272 - val_precision: 0.7744 - val_recall: 0.9240\n",
            "Epoch 13/15\n",
            "213/213 [==============================] - 1s 6ms/step - loss: 0.4012 - accuracy: 0.8200 - precision: 0.7826 - recall: 0.8859 - val_loss: 0.3831 - val_accuracy: 0.8262 - val_precision: 0.7769 - val_recall: 0.9158\n",
            "Epoch 14/15\n",
            "213/213 [==============================] - 2s 8ms/step - loss: 0.4120 - accuracy: 0.8159 - precision: 0.7782 - recall: 0.8833 - val_loss: 0.3903 - val_accuracy: 0.8200 - val_precision: 0.7849 - val_recall: 0.8822\n",
            "Epoch 15/15\n",
            "213/213 [==============================] - 2s 7ms/step - loss: 0.4078 - accuracy: 0.8097 - precision: 0.7749 - recall: 0.8727 - val_loss: 0.3822 - val_accuracy: 0.8269 - val_precision: 0.7817 - val_recall: 0.9075\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5bc6624c50>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhkSEThVKEdm"
      },
      "source": [
        "Comment the performance of your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dghb5Pkaj4fs"
      },
      "source": [
        "**[Share your Zaka here]**\n",
        "**The recall decreased and its now the same on training and testing set**\n",
        "**The accuracy of the test set is now better than that on training, same for precision**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXf6cpO_KWTs"
      },
      "source": [
        "###Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2rMJJEcNDil"
      },
      "source": [
        "Now we will tune some hyperparameters of our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQl4VxrOLQGO"
      },
      "source": [
        "We start by wrapping our model inside a kerasClassifier to be able to use it in Scikit Learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYBO5H5LLW4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0baaff95-acd9-4ebe-ba03-77360b0696c2"
      },
      "source": [
        "#Test Your Zaka\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "model1 = KerasClassifier(build_fn = batch_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIqMITAEKoue"
      },
      "source": [
        "We will tune the batch size (it can be 50 or 100) and the number of epochs (it can be 50 or 100).\n",
        "We will use a 3 folds cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_XXldXwJ-Ch"
      },
      "source": [
        "#Test Your Zaka\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "batches = [50,100]\n",
        "epochs = [50,100]\n",
        "params ={'batch_size':batches,'epochs': epochs}\n",
        "tune = GridSearchCV(model1, param_grid= params, cv=3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oMDOqprkS8S"
      },
      "source": [
        "Find the best parameters according to the Grid Search you have done, and the accuracy for the best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fom1lr4pMku4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14b17513-e225-474f-adce-67105f1485f6"
      },
      "source": [
        "#Test Your Zaka\n",
        "best_p=tune.fit(x_train, y_train,verbose=0)\n",
        "best_p.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8502 - precision: 0.7964 - recall: 0.9304\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.3593 - accuracy: 0.8448 - precision: 0.7928 - recall: 0.9391\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.3457 - accuracy: 0.8452 - precision: 0.7955 - recall: 0.9337\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8673 - precision: 0.8038 - recall: 0.9629\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.3283 - accuracy: 0.8585 - precision: 0.8004 - recall: 0.9600\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.2950 - accuracy: 0.8690 - precision: 0.8204 - recall: 0.9485\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8480 - precision: 0.8200 - recall: 0.8816\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8298 - precision: 0.7815 - recall: 0.9217\n",
            "23/23 [==============================] - 1s 2ms/step - loss: 0.3250 - accuracy: 0.8602 - precision: 0.8282 - recall: 0.9127\n",
            "23/23 [==============================] - 1s 3ms/step - loss: 0.3383 - accuracy: 0.8532 - precision: 0.8218 - recall: 0.8924\n",
            "23/23 [==============================] - 1s 3ms/step - loss: 0.3361 - accuracy: 0.8611 - precision: 0.8154 - recall: 0.9382\n",
            "23/23 [==============================] - 1s 2ms/step - loss: 0.3095 - accuracy: 0.8726 - precision: 0.8403 - recall: 0.9232\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 50, 'epochs': 100}"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqKDaC5aUQtc"
      },
      "source": [
        "Fit the model on the best hyperparameters we obtained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiauYJNtQXLB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc5901b5-8c17-4832-8c5a-9c7c950349d2"
      },
      "source": [
        "#Test Your Zaka\n",
        "modelb.fit(x_train, y_train,validation_data=(x_test, y_test), epochs=100, batch_size=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "137/137 [==============================] - 1s 11ms/step - loss: 0.3817 - accuracy: 0.8284 - precision: 0.7901 - recall: 0.8941 - val_loss: 0.3764 - val_accuracy: 0.8306 - val_precision: 0.8088 - val_recall: 0.8664\n",
            "Epoch 2/100\n",
            "137/137 [==============================] - 1s 10ms/step - loss: 0.3797 - accuracy: 0.8276 - precision: 0.7930 - recall: 0.8865 - val_loss: 0.3606 - val_accuracy: 0.8378 - val_precision: 0.7978 - val_recall: 0.9055\n",
            "Epoch 3/100\n",
            "137/137 [==============================] - 2s 11ms/step - loss: 0.3713 - accuracy: 0.8347 - precision: 0.7954 - recall: 0.9009 - val_loss: 0.3706 - val_accuracy: 0.8334 - val_precision: 0.8130 - val_recall: 0.8664\n",
            "Epoch 4/100\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3687 - accuracy: 0.8312 - precision: 0.7968 - recall: 0.8889 - val_loss: 0.3616 - val_accuracy: 0.8450 - val_precision: 0.7920 - val_recall: 0.9363\n",
            "Epoch 5/100\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3739 - accuracy: 0.8284 - precision: 0.7936 - recall: 0.8874 - val_loss: 0.3678 - val_accuracy: 0.8382 - val_precision: 0.7872 - val_recall: 0.9274\n",
            "Epoch 6/100\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3710 - accuracy: 0.8338 - precision: 0.8001 - recall: 0.8897 - val_loss: 0.3631 - val_accuracy: 0.8372 - val_precision: 0.7951 - val_recall: 0.9089\n",
            "Epoch 7/100\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.3686 - accuracy: 0.8382 - precision: 0.8018 - recall: 0.8983 - val_loss: 0.3557 - val_accuracy: 0.8478 - val_precision: 0.8027 - val_recall: 0.9226\n",
            "Epoch 8/100\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3636 - accuracy: 0.8375 - precision: 0.7969 - recall: 0.9056 - val_loss: 0.3582 - val_accuracy: 0.8440 - val_precision: 0.8139 - val_recall: 0.8925\n",
            "Epoch 9/100\n",
            "137/137 [==============================] - 1s 9ms/step - loss: 0.3673 - accuracy: 0.8339 - precision: 0.7995 - recall: 0.8912 - val_loss: 0.3615 - val_accuracy: 0.8392 - val_precision: 0.7965 - val_recall: 0.9116\n",
            "Epoch 10/100\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.3611 - accuracy: 0.8386 - precision: 0.8058 - recall: 0.8921 - val_loss: 0.3587 - val_accuracy: 0.8492 - val_precision: 0.8043 - val_recall: 0.9233\n",
            "Epoch 11/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.3660 - accuracy: 0.8369 - precision: 0.7998 - recall: 0.8986 - val_loss: 0.3595 - val_accuracy: 0.8426 - val_precision: 0.7999 - val_recall: 0.9144\n",
            "Epoch 12/100\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3552 - accuracy: 0.8401 - precision: 0.8052 - recall: 0.8971 - val_loss: 0.3667 - val_accuracy: 0.8389 - val_precision: 0.8173 - val_recall: 0.8733\n",
            "Epoch 13/100\n",
            "137/137 [==============================] - 1s 9ms/step - loss: 0.3624 - accuracy: 0.8385 - precision: 0.8073 - recall: 0.8892 - val_loss: 0.3641 - val_accuracy: 0.8406 - val_precision: 0.7970 - val_recall: 0.9144\n",
            "Epoch 14/100\n",
            "137/137 [==============================] - 1s 9ms/step - loss: 0.3564 - accuracy: 0.8404 - precision: 0.8040 - recall: 0.9000 - val_loss: 0.3510 - val_accuracy: 0.8481 - val_precision: 0.7986 - val_recall: 0.9315\n",
            "Epoch 15/100\n",
            "137/137 [==============================] - 1s 10ms/step - loss: 0.3577 - accuracy: 0.8435 - precision: 0.8062 - recall: 0.9041 - val_loss: 0.3563 - val_accuracy: 0.8433 - val_precision: 0.8109 - val_recall: 0.8959\n",
            "Epoch 16/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3577 - accuracy: 0.8466 - precision: 0.8092 - recall: 0.9068 - val_loss: 0.3542 - val_accuracy: 0.8461 - val_precision: 0.8306 - val_recall: 0.8699\n",
            "Epoch 17/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3506 - accuracy: 0.8435 - precision: 0.8097 - recall: 0.8980 - val_loss: 0.3688 - val_accuracy: 0.8365 - val_precision: 0.7747 - val_recall: 0.9493\n",
            "Epoch 18/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3509 - accuracy: 0.8467 - precision: 0.8096 - recall: 0.9065 - val_loss: 0.3545 - val_accuracy: 0.8457 - val_precision: 0.8042 - val_recall: 0.9144\n",
            "Epoch 19/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3459 - accuracy: 0.8516 - precision: 0.8204 - recall: 0.9000 - val_loss: 0.3360 - val_accuracy: 0.8636 - val_precision: 0.8195 - val_recall: 0.9329\n",
            "Epoch 20/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3483 - accuracy: 0.8458 - precision: 0.8114 - recall: 0.9009 - val_loss: 0.3390 - val_accuracy: 0.8560 - val_precision: 0.8152 - val_recall: 0.9212\n",
            "Epoch 21/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3431 - accuracy: 0.8491 - precision: 0.8137 - recall: 0.9053 - val_loss: 0.3415 - val_accuracy: 0.8505 - val_precision: 0.8133 - val_recall: 0.9103\n",
            "Epoch 22/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3440 - accuracy: 0.8466 - precision: 0.8124 - recall: 0.9012 - val_loss: 0.3369 - val_accuracy: 0.8591 - val_precision: 0.8240 - val_recall: 0.9137\n",
            "Epoch 23/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3364 - accuracy: 0.8557 - precision: 0.8221 - recall: 0.9077 - val_loss: 0.3397 - val_accuracy: 0.8557 - val_precision: 0.8150 - val_recall: 0.9205\n",
            "Epoch 24/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3339 - accuracy: 0.8532 - precision: 0.8203 - recall: 0.9044 - val_loss: 0.3393 - val_accuracy: 0.8584 - val_precision: 0.8167 - val_recall: 0.9247\n",
            "Epoch 25/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3423 - accuracy: 0.8538 - precision: 0.8188 - recall: 0.9086 - val_loss: 0.3429 - val_accuracy: 0.8533 - val_precision: 0.7972 - val_recall: 0.9479\n",
            "Epoch 26/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3357 - accuracy: 0.8560 - precision: 0.8185 - recall: 0.9147 - val_loss: 0.3443 - val_accuracy: 0.8546 - val_precision: 0.8372 - val_recall: 0.8808\n",
            "Epoch 27/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3369 - accuracy: 0.8528 - precision: 0.8208 - recall: 0.9024 - val_loss: 0.3393 - val_accuracy: 0.8543 - val_precision: 0.7976 - val_recall: 0.9500\n",
            "Epoch 28/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3437 - accuracy: 0.8475 - precision: 0.8141 - recall: 0.9003 - val_loss: 0.3399 - val_accuracy: 0.8519 - val_precision: 0.7968 - val_recall: 0.9452\n",
            "Epoch 29/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3323 - accuracy: 0.8548 - precision: 0.8222 - recall: 0.9053 - val_loss: 0.3456 - val_accuracy: 0.8464 - val_precision: 0.7911 - val_recall: 0.9418\n",
            "Epoch 30/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.3259 - accuracy: 0.8604 - precision: 0.8313 - recall: 0.9041 - val_loss: 0.3310 - val_accuracy: 0.8591 - val_precision: 0.8109 - val_recall: 0.9370\n",
            "Epoch 31/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3334 - accuracy: 0.8563 - precision: 0.8266 - recall: 0.9015 - val_loss: 0.3334 - val_accuracy: 0.8608 - val_precision: 0.8141 - val_recall: 0.9356\n",
            "Epoch 32/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3334 - accuracy: 0.8523 - precision: 0.8190 - recall: 0.9044 - val_loss: 0.3297 - val_accuracy: 0.8591 - val_precision: 0.8124 - val_recall: 0.9342\n",
            "Epoch 33/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3371 - accuracy: 0.8582 - precision: 0.8278 - recall: 0.9044 - val_loss: 0.3464 - val_accuracy: 0.8447 - val_precision: 0.8076 - val_recall: 0.9055\n",
            "Epoch 34/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3398 - accuracy: 0.8551 - precision: 0.8224 - recall: 0.9056 - val_loss: 0.3316 - val_accuracy: 0.8581 - val_precision: 0.8121 - val_recall: 0.9322\n",
            "Epoch 35/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3268 - accuracy: 0.8588 - precision: 0.8248 - recall: 0.9109 - val_loss: 0.3353 - val_accuracy: 0.8533 - val_precision: 0.8035 - val_recall: 0.9356\n",
            "Epoch 36/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3241 - accuracy: 0.8594 - precision: 0.8266 - recall: 0.9094 - val_loss: 0.3423 - val_accuracy: 0.8598 - val_precision: 0.8384 - val_recall: 0.8918\n",
            "Epoch 37/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.3161 - accuracy: 0.8607 - precision: 0.8272 - recall: 0.9118 - val_loss: 0.3242 - val_accuracy: 0.8615 - val_precision: 0.8106 - val_recall: 0.9438\n",
            "Epoch 38/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3268 - accuracy: 0.8582 - precision: 0.8265 - recall: 0.9065 - val_loss: 0.3409 - val_accuracy: 0.8574 - val_precision: 0.7919 - val_recall: 0.9699\n",
            "Epoch 39/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.3431 - accuracy: 0.8569 - precision: 0.8246 - recall: 0.9065 - val_loss: 0.3291 - val_accuracy: 0.8632 - val_precision: 0.8175 - val_recall: 0.9356\n",
            "Epoch 40/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.3215 - accuracy: 0.8605 - precision: 0.8269 - recall: 0.9118 - val_loss: 0.3246 - val_accuracy: 0.8649 - val_precision: 0.8270 - val_recall: 0.9233\n",
            "Epoch 41/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.3234 - accuracy: 0.8604 - precision: 0.8311 - recall: 0.9044 - val_loss: 0.3252 - val_accuracy: 0.8711 - val_precision: 0.8379 - val_recall: 0.9205\n",
            "Epoch 42/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3198 - accuracy: 0.8613 - precision: 0.8298 - recall: 0.9089 - val_loss: 0.3194 - val_accuracy: 0.8704 - val_precision: 0.8364 - val_recall: 0.9212\n",
            "Epoch 43/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3159 - accuracy: 0.8676 - precision: 0.8340 - recall: 0.9177 - val_loss: 0.3283 - val_accuracy: 0.8660 - val_precision: 0.8081 - val_recall: 0.9603\n",
            "Epoch 44/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3213 - accuracy: 0.8602 - precision: 0.8304 - recall: 0.9053 - val_loss: 0.3183 - val_accuracy: 0.8656 - val_precision: 0.8252 - val_recall: 0.9281\n",
            "Epoch 45/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3190 - accuracy: 0.8682 - precision: 0.8362 - recall: 0.9156 - val_loss: 0.3202 - val_accuracy: 0.8646 - val_precision: 0.8310 - val_recall: 0.9158\n",
            "Epoch 46/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.3183 - accuracy: 0.8614 - precision: 0.8288 - recall: 0.9109 - val_loss: 0.3173 - val_accuracy: 0.8666 - val_precision: 0.8156 - val_recall: 0.9479\n",
            "Epoch 47/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3088 - accuracy: 0.8680 - precision: 0.8356 - recall: 0.9162 - val_loss: 0.3107 - val_accuracy: 0.8718 - val_precision: 0.8299 - val_recall: 0.9356\n",
            "Epoch 48/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3223 - accuracy: 0.8586 - precision: 0.8239 - recall: 0.9121 - val_loss: 0.3052 - val_accuracy: 0.8738 - val_precision: 0.8273 - val_recall: 0.9452\n",
            "Epoch 49/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3175 - accuracy: 0.8595 - precision: 0.8292 - recall: 0.9053 - val_loss: 0.3124 - val_accuracy: 0.8639 - val_precision: 0.8251 - val_recall: 0.9240\n",
            "Epoch 50/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3110 - accuracy: 0.8648 - precision: 0.8316 - recall: 0.9147 - val_loss: 0.3144 - val_accuracy: 0.8704 - val_precision: 0.8186 - val_recall: 0.9521\n",
            "Epoch 51/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.3136 - accuracy: 0.8664 - precision: 0.8349 - recall: 0.9133 - val_loss: 0.3128 - val_accuracy: 0.8762 - val_precision: 0.8253 - val_recall: 0.9548\n",
            "Epoch 52/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3074 - accuracy: 0.8732 - precision: 0.8397 - recall: 0.9224 - val_loss: 0.3096 - val_accuracy: 0.8762 - val_precision: 0.8273 - val_recall: 0.9514\n",
            "Epoch 53/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3098 - accuracy: 0.8642 - precision: 0.8314 - recall: 0.9136 - val_loss: 0.3130 - val_accuracy: 0.8649 - val_precision: 0.8226 - val_recall: 0.9308\n",
            "Epoch 54/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3102 - accuracy: 0.8667 - precision: 0.8370 - recall: 0.9106 - val_loss: 0.3099 - val_accuracy: 0.8721 - val_precision: 0.8382 - val_recall: 0.9226\n",
            "Epoch 55/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.3123 - accuracy: 0.8680 - precision: 0.8322 - recall: 0.9218 - val_loss: 0.3112 - val_accuracy: 0.8697 - val_precision: 0.8234 - val_recall: 0.9418\n",
            "Epoch 56/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.3048 - accuracy: 0.8698 - precision: 0.8361 - recall: 0.9197 - val_loss: 0.3144 - val_accuracy: 0.8690 - val_precision: 0.8201 - val_recall: 0.9459\n",
            "Epoch 57/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3128 - accuracy: 0.8657 - precision: 0.8320 - recall: 0.9162 - val_loss: 0.3165 - val_accuracy: 0.8673 - val_precision: 0.8165 - val_recall: 0.9479\n",
            "Epoch 58/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3122 - accuracy: 0.8655 - precision: 0.8336 - recall: 0.9133 - val_loss: 0.3090 - val_accuracy: 0.8745 - val_precision: 0.8381 - val_recall: 0.9288\n",
            "Epoch 59/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3033 - accuracy: 0.8713 - precision: 0.8420 - recall: 0.9138 - val_loss: 0.3132 - val_accuracy: 0.8762 - val_precision: 0.8238 - val_recall: 0.9575\n",
            "Epoch 60/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3041 - accuracy: 0.8755 - precision: 0.8405 - recall: 0.9268 - val_loss: 0.3023 - val_accuracy: 0.8790 - val_precision: 0.8328 - val_recall: 0.9486\n",
            "Epoch 61/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3039 - accuracy: 0.8688 - precision: 0.8409 - recall: 0.9094 - val_loss: 0.3084 - val_accuracy: 0.8732 - val_precision: 0.8303 - val_recall: 0.9384\n",
            "Epoch 62/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3094 - accuracy: 0.8682 - precision: 0.8362 - recall: 0.9156 - val_loss: 0.3141 - val_accuracy: 0.8728 - val_precision: 0.8239 - val_recall: 0.9486\n",
            "Epoch 63/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2951 - accuracy: 0.8747 - precision: 0.8421 - recall: 0.9221 - val_loss: 0.3084 - val_accuracy: 0.8666 - val_precision: 0.8255 - val_recall: 0.9301\n",
            "Epoch 64/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3002 - accuracy: 0.8738 - precision: 0.8450 - recall: 0.9153 - val_loss: 0.3218 - val_accuracy: 0.8708 - val_precision: 0.8117 - val_recall: 0.9658\n",
            "Epoch 65/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2996 - accuracy: 0.8710 - precision: 0.8407 - recall: 0.9153 - val_loss: 0.3091 - val_accuracy: 0.8738 - val_precision: 0.8325 - val_recall: 0.9363\n",
            "Epoch 66/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3076 - accuracy: 0.8717 - precision: 0.8363 - recall: 0.9241 - val_loss: 0.3101 - val_accuracy: 0.8752 - val_precision: 0.8270 - val_recall: 0.9493\n",
            "Epoch 67/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3397 - accuracy: 0.8525 - precision: 0.8265 - recall: 0.8921 - val_loss: 0.3280 - val_accuracy: 0.8612 - val_precision: 0.8254 - val_recall: 0.9164\n",
            "Epoch 68/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3103 - accuracy: 0.8677 - precision: 0.8348 - recall: 0.9168 - val_loss: 0.3114 - val_accuracy: 0.8708 - val_precision: 0.8229 - val_recall: 0.9452\n",
            "Epoch 69/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2998 - accuracy: 0.8695 - precision: 0.8379 - recall: 0.9162 - val_loss: 0.3119 - val_accuracy: 0.8701 - val_precision: 0.8334 - val_recall: 0.9253\n",
            "Epoch 70/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.3096 - accuracy: 0.8697 - precision: 0.8395 - recall: 0.9138 - val_loss: 0.3100 - val_accuracy: 0.8762 - val_precision: 0.8312 - val_recall: 0.9445\n",
            "Epoch 71/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.3028 - accuracy: 0.8748 - precision: 0.8391 - recall: 0.9274 - val_loss: 0.3132 - val_accuracy: 0.8687 - val_precision: 0.8200 - val_recall: 0.9452\n",
            "Epoch 72/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.3035 - accuracy: 0.8722 - precision: 0.8406 - recall: 0.9183 - val_loss: 0.3104 - val_accuracy: 0.8756 - val_precision: 0.8405 - val_recall: 0.9274\n",
            "Epoch 73/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.3008 - accuracy: 0.8757 - precision: 0.8452 - recall: 0.9197 - val_loss: 0.2985 - val_accuracy: 0.8831 - val_precision: 0.8397 - val_recall: 0.9473\n",
            "Epoch 74/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2979 - accuracy: 0.8726 - precision: 0.8456 - recall: 0.9115 - val_loss: 0.3046 - val_accuracy: 0.8783 - val_precision: 0.8396 - val_recall: 0.9356\n",
            "Epoch 75/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3008 - accuracy: 0.8749 - precision: 0.8450 - recall: 0.9183 - val_loss: 0.3117 - val_accuracy: 0.8797 - val_precision: 0.8264 - val_recall: 0.9616\n",
            "Epoch 76/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.3003 - accuracy: 0.8738 - precision: 0.8430 - recall: 0.9186 - val_loss: 0.3062 - val_accuracy: 0.8773 - val_precision: 0.8397 - val_recall: 0.9329\n",
            "Epoch 77/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3007 - accuracy: 0.8724 - precision: 0.8404 - recall: 0.9194 - val_loss: 0.2934 - val_accuracy: 0.8814 - val_precision: 0.8451 - val_recall: 0.9342\n",
            "Epoch 78/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2965 - accuracy: 0.8705 - precision: 0.8443 - recall: 0.9086 - val_loss: 0.3058 - val_accuracy: 0.8762 - val_precision: 0.8407 - val_recall: 0.9288\n",
            "Epoch 79/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2886 - accuracy: 0.8749 - precision: 0.8450 - recall: 0.9183 - val_loss: 0.3023 - val_accuracy: 0.8817 - val_precision: 0.8324 - val_recall: 0.9562\n",
            "Epoch 80/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.3000 - accuracy: 0.8701 - precision: 0.8423 - recall: 0.9106 - val_loss: 0.3018 - val_accuracy: 0.8738 - val_precision: 0.8317 - val_recall: 0.9377\n",
            "Epoch 81/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.2906 - accuracy: 0.8801 - precision: 0.8492 - recall: 0.9241 - val_loss: 0.3109 - val_accuracy: 0.8762 - val_precision: 0.8285 - val_recall: 0.9493\n",
            "Epoch 82/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.2959 - accuracy: 0.8785 - precision: 0.8458 - recall: 0.9256 - val_loss: 0.3055 - val_accuracy: 0.8773 - val_precision: 0.8319 - val_recall: 0.9459\n",
            "Epoch 83/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2929 - accuracy: 0.8766 - precision: 0.8471 - recall: 0.9188 - val_loss: 0.3122 - val_accuracy: 0.8711 - val_precision: 0.8301 - val_recall: 0.9336\n",
            "Epoch 84/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2900 - accuracy: 0.8785 - precision: 0.8503 - recall: 0.9186 - val_loss: 0.2963 - val_accuracy: 0.8855 - val_precision: 0.8429 - val_recall: 0.9479\n",
            "Epoch 85/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2881 - accuracy: 0.8832 - precision: 0.8510 - recall: 0.9288 - val_loss: 0.3012 - val_accuracy: 0.8735 - val_precision: 0.8257 - val_recall: 0.9473\n",
            "Epoch 86/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2974 - accuracy: 0.8745 - precision: 0.8471 - recall: 0.9138 - val_loss: 0.3040 - val_accuracy: 0.8773 - val_precision: 0.8452 - val_recall: 0.9240\n",
            "Epoch 87/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2858 - accuracy: 0.8805 - precision: 0.8526 - recall: 0.9200 - val_loss: 0.2870 - val_accuracy: 0.8896 - val_precision: 0.8508 - val_recall: 0.9452\n",
            "Epoch 88/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2923 - accuracy: 0.8770 - precision: 0.8469 - recall: 0.9203 - val_loss: 0.2991 - val_accuracy: 0.8814 - val_precision: 0.8543 - val_recall: 0.9199\n",
            "Epoch 89/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3190 - accuracy: 0.8613 - precision: 0.8325 - recall: 0.9044 - val_loss: 0.3031 - val_accuracy: 0.8793 - val_precision: 0.8407 - val_recall: 0.9363\n",
            "Epoch 90/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3180 - accuracy: 0.8670 - precision: 0.8368 - recall: 0.9118 - val_loss: 0.3031 - val_accuracy: 0.8817 - val_precision: 0.8348 - val_recall: 0.9521\n",
            "Epoch 91/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2971 - accuracy: 0.8702 - precision: 0.8377 - recall: 0.9183 - val_loss: 0.3180 - val_accuracy: 0.8732 - val_precision: 0.8195 - val_recall: 0.9575\n",
            "Epoch 92/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3052 - accuracy: 0.8714 - precision: 0.8428 - recall: 0.9130 - val_loss: 0.3001 - val_accuracy: 0.8790 - val_precision: 0.8415 - val_recall: 0.9342\n",
            "Epoch 93/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3007 - accuracy: 0.8788 - precision: 0.8496 - recall: 0.9203 - val_loss: 0.3041 - val_accuracy: 0.8735 - val_precision: 0.8177 - val_recall: 0.9616\n",
            "Epoch 94/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2926 - accuracy: 0.8755 - precision: 0.8449 - recall: 0.9197 - val_loss: 0.2992 - val_accuracy: 0.8828 - val_precision: 0.8384 - val_recall: 0.9486\n",
            "Epoch 95/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2978 - accuracy: 0.8748 - precision: 0.8436 - recall: 0.9200 - val_loss: 0.3070 - val_accuracy: 0.8687 - val_precision: 0.8286 - val_recall: 0.9301\n",
            "Epoch 96/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2970 - accuracy: 0.8716 - precision: 0.8390 - recall: 0.9194 - val_loss: 0.3129 - val_accuracy: 0.8680 - val_precision: 0.8383 - val_recall: 0.9123\n",
            "Epoch 97/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2945 - accuracy: 0.8771 - precision: 0.8458 - recall: 0.9224 - val_loss: 0.3011 - val_accuracy: 0.8821 - val_precision: 0.8366 - val_recall: 0.9500\n",
            "Epoch 98/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2895 - accuracy: 0.8770 - precision: 0.8459 - recall: 0.9218 - val_loss: 0.3077 - val_accuracy: 0.8773 - val_precision: 0.8276 - val_recall: 0.9534\n",
            "Epoch 99/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.2852 - accuracy: 0.8820 - precision: 0.8492 - recall: 0.9288 - val_loss: 0.3055 - val_accuracy: 0.8735 - val_precision: 0.8332 - val_recall: 0.9342\n",
            "Epoch 100/100\n",
            "137/137 [==============================] - 1s 6ms/step - loss: 0.2960 - accuracy: 0.8736 - precision: 0.8429 - recall: 0.9183 - val_loss: 0.2954 - val_accuracy: 0.8852 - val_precision: 0.8436 - val_recall: 0.9459\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5bc688c650>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wih9ltzbVH5F"
      },
      "source": [
        "Comment the performance of your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ59ggoxkniT"
      },
      "source": [
        "**[Share Your Zaka here]**\n",
        "\n",
        "**The loss is the smaller compared to the previous model**\n",
        "\n",
        "**The training accuracy increased by 7% than the previous model and the validation accuracy increased by 6%**\n",
        "\n",
        "**The training precision increased by 7% than the previous model and the validation precision increased by 6% as well**\n",
        "\n",
        "**The training recall and the validation recall increased by 4% than the previous model** \n",
        "\n",
        "**Overall the model performance is much better than before, and if we tune other hyperparamters like the number of hidden layers and the optimizer for example we could even achieve a better perfomance**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QILPt2Cg3D8i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
